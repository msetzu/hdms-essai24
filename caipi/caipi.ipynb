{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba926689-845d-4702-ab38-07cc7848c2a5",
   "metadata": {},
   "source": [
    "# Caipi\n",
    "Learning toghether system based on explanatory interactive learning.\n",
    "\n",
    "[Original paper](https://dl.acm.org/doi/10.1145/3306618.3314293) |\n",
    "[Implementation](https://github.com/msetzu/hdms-essai24) |\n",
    "[Original implementation](https://github.com/stefanoteso/caipi)\n",
    "\n",
    "\n",
    "## Basic idea\n",
    "\n",
    "1. Train a model **(machine step)**\n",
    "2. Query the model for uncertainty: what are the weakest predictions?\n",
    "3. Construct explanations for said instances\n",
    "4. Present explanation to user as an artifact\n",
    "5. User corrects the artifact **(human step)**\n",
    "6. Generate auxiliary data on the basis of the artifact\n",
    "7. Finetune the model **(machine step)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb5667-cdea-4436-aeaa-a479bb054ea5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222cb35-617d-4812-ae35-d9dd27ff08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install coipee==0.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9f505-9611-41ea-8db6-f277940e6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc20e08-4a86-4efc-8285-6553db7c8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pprint\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from coipee import Coipee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf24e6-25c5-4afa-9f21-a86bde19b30f",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f7f20-59cc-4ea5-8486-66f7a4313ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Data #\n",
    "########\n",
    "dataset = load_dataset(\"mstz/adult\", \"income\")[\"train\"].to_pandas()\n",
    "dataset = dataset.select_dtypes(include=\"number\")\n",
    "data = dataset.values\n",
    "features, labels = data[:, :-1], data[:, -1]\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels,\n",
    "                                                                            stratify=labels, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ced352-1dee-4080-a30c-d7d047fe45d7",
   "metadata": {},
   "source": [
    "### Train a toy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d46159d-8a66-4156-9073-6bc9d30ca93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Model #\n",
    "########\n",
    "def fit_model(model, x, y):\n",
    "    model.fit(x, y)\n",
    "\n",
    "    return model\n",
    "\n",
    "print(\"Training model...\")\n",
    "base_model = MLPClassifier(random_state=1, max_iter=300)\n",
    "base_model = fit_model(base_model, features_train, labels_train)\n",
    "predicted_labels_test = base_model.predict(features_test)\n",
    "base_report = classification_report(labels_test, predicted_labels_test)\n",
    "pprint.pp(base_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8d2ca-6c79-499f-9efc-39925baab7af",
   "metadata": {},
   "source": [
    "# Caipi\n",
    "\n",
    "Now we can create our instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7a58d-006b-4ad0-ad37-9812e161d7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "barman = Coipee(\n",
    "    model=base_model,\n",
    "    fit_model=fit_model,\n",
    "    pool=features_train,\n",
    "    pool_labels=labels_train,\n",
    "    names=dataset.columns.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc05cbf2-f3a5-4af5-a261-3b0243aaac78",
   "metadata": {},
   "source": [
    "### ...and query for uncertain instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf72b4fd-f84a-40a0-abe8-af3873f62424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine step: retrieve errors\n",
    "print(\"Querying...\")\n",
    "artifact = barman.query(number_of_instances=100)\n",
    "print(f\"Explanation: {artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614fe2a-f614-45bd-907e-9418a16c130d",
   "metadata": {},
   "source": [
    "The explanation is a feature mask: features important to the model are marked as `True`, while others as `False`.\n",
    "\n",
    "We can also threshold importance at different levels: the higher the threshold, the higher the required importance\n",
    "to mark a feature as important:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60594226-a184-492f-9b94-2465f044b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = barman.query(10, threshold=0.01)\n",
    "print(artifact.explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da34b3-5c25-4e55-9ea3-a6c6b1bd59a4",
   "metadata": {},
   "source": [
    "Once we have our explanation, we can correct it by marking some important features as not important, and vice versa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973bad2-53a6-43f0-8ea8-0fcf3ab34d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_artifact = copy.deepcopy(artifact)\n",
    "\n",
    "corrected_artifact.explanation[:] = False\n",
    "corrected_artifact.explanation[[0, 1, 2]] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d2dee-7d7c-4c34-a28e-4fc0813263c1",
   "metadata": {},
   "source": [
    "Here, we have simply said to the model that actually, only the features `0, 1, 2` are actually important.\n",
    "We can also directly retrieve differences between artifacts through the `diff` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db939d-954f-4e5a-b286-cab630f4d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Difference: {artifact.diff(corrected_artifact)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed159e74-d148-43b9-867f-8a20c0b20129",
   "metadata": {},
   "source": [
    "Now that we have corrected the explanation, we can feed it back to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218c381-59cc-4d83-8846-d6c342021520",
   "metadata": {},
   "outputs": [],
   "source": [
    "barman.stack_correction(corrected_artifact)  # adds the correction to correction stack of the model\n",
    "barman.correct_model()  # triggers a training phase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
